train_path = data/datasets/conll04/conll04_train_dep_context.json
valid_path = data/datasets/conll04/conll04_dev_dep_context.json
save_path = data/save/
init_eval = False
save_optimizer = False
train_log_iter = 1
final_eval = False
train_batch_size = 8
epochs = 30
neg_entity_count = 100
neg_relation_count = 100
lr = 5e-05
lr_warmup = 0.1
weight_decay = 0.01
max_grad_norm = 1.0
full_graph_retain_rate = 1.0
dt_graph_retain_rate = 1.0
tw_grad_flow_token = True
tw_grad_flow_subword = True
trigger_grad_flow = True
split_epoch = 10
config = configs/example.conf
types_path = data/datasets/conll04/conll04_types.json
tokenizer_path = bert-base-cased
max_span_size = 10
lowercase = False
sampling_processes = 0
sampling_limit = 100
label = conll04_train
log_path = data/save/
store_predictions = False
store_examples = False
example_count = None
debug = False
model_path = bert-base-cased
model_type = trimf
cpu = False
device_id = 3
eval_batch_size = 4
max_pairs = 1000
rel_filter_threshold = 0.35
size_embedding = 25
prop_drop = 0.5
freeze_transformer = False
no_overlapping = False
syn_graph = True
sema_graph = True
fusion_rgcn = True
tw_rel_atten_token = True
tw_ent_atten_token = True
tw_rel_atten_subword = True
tw_ent_atten_subword = True
trigger_attn = True
seed = 732